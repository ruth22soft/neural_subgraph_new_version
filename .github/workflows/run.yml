name: Run Decoder

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

jobs:
  run-decoder:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      # Pull prebuilt Docker image from Docker Hub
      - name: Pull prebuilt Docker image
        run: |
          docker pull samribahta/decoder-image:latest
      - name: Create output directories
        run: |
          mkdir -p ${{ github.workspace }}/plots/cluster
          mkdir -p ${{ github.workspace }}/results
          chmod -R 777 ${{ github.workspace }}/plots
          chmod -R 777 ${{ github.workspace }}/results
      - name: Check available processors and usage percentage
        id: cpu-check
        run: |
          TOTAL_CPUS=$(nproc)
          USED_CPUS=4
          PERCENT_USED=$(( 100 * USED_CPUS / TOTAL_CPUS ))
          echo "Total available processors: $TOTAL_CPUS"
          echo "Processors used for decoder: $USED_CPUS"
          echo "Percent of processors used: ${PERCENT_USED}%"
          echo "total_cpus=$TOTAL_CPUS" >> $GITHUB_OUTPUT
          echo "percent_used=$PERCENT_USED" >> $GITHUB_OUTPUT
      #  Run decoder using prebuilt Docker image
      # - name: Download CAIDA dataset
      #   run: wget https://drive.google.com/file/d/1z-YyZi-STs6A3-CB07Lh_0qJBXcO2r4u/view?usp=sharing -O directed_caida.pkl
        
      - name: Run decoder in Docker container
        run: |
          docker run --rm \
            -v ${{ github.workspace }}:/app \
            -e PYTHONUNBUFFERED=1 \
            samribahta/decoder-image:latest \
            bash -c "
              set -e
              echo 'Starting decoder run...'
              python -m subgraph_mining.decoder \
                --dataset=directed_caida.pkl \
                --n_trials=200 \
                --node_anchored \
                --out_path=/app/results/patterns.pkl \
                --graph_type=directed
              echo 'Checking output directories...'
              ls -la /app/plots/cluster
              ls -la /app/results
            "
      # - name: Run pattern counter in Docker container
      #   run: |
      #     docker run --rm \
      #       -v ${{ github.workspace }}:/app \
      #       -e PYTHONUNBUFFERED=1 \
      #       samribahta/decoder-image:latest \
      #       bash -c "
      #         set -e
      #         export PYTHONPATH=/app
      #         echo 'Running pattern counter...'
      #         python -m analyze.count_patterns \
      #           --dataset=graph.pkl \
      #           --queries_path=results/patterns.pkl \
      #           --out_path=results/ \
      #           --node_anchored \
      #           --preserve_labels
      #         echo 'Counting completed.'
      #         ls -la /app/results
      #       "
      # - name: Run matcher in Docker container
      #   run: |
      #     docker run --rm \
      #       -v ${{ github.workspace }}:/app \
      #       -e PYTHONUNBUFFERED=1 \
      #       samribahta/decoder-image:latest \
      #       bash -c "
      #         set -e
      #         echo 'Starting matcher run on custom gene graph...'
      #         python -m subgraph_matching.train \
      #           --dataset=graph \
      #           --graph_pkl_path=graph.pkl \
      #           --node_anchored \
      #           --batch_size 16 \
      #           --val_size 128
      #         echo 'Checking output directories...'
      #         ls -la /app/results
      #         ls -la /app/plots
      #       "
      - name: Check for generated files
        run: |
          echo "Checking plots directory:"
          ls -R plots/ || echo "No plots directory found"
          echo "Checking results directory:"
          ls -R results/ || echo "No results directory found"
      - name: Upload plots as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: decoder-plots
          path: |
            plots/
            results/
          retention-days: 7
          if-no-files-found: warn
